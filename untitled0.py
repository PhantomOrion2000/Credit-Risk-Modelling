# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gxy3-PNk0hhb3vcwyAKwXOuExFO2iyff
"""

!pip install openpyxl

!pip install statsmodels

!pip install xgboost

import pandas as pd
import numpy as np
from statsmodels.stats.outliers_influence import variance_inflation_factor
from scipy.stats import f_oneway

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
import xgboost as xgb
from sklearn.metrics import r2_score, accuracy_score, classification_report, precision_recall_fscore_support

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/credit risk modelling/merged_data.xlsx')

df.head()

df.info()

categorical_columns = []

for i in list(df.columns):
  if df[i].dtype == 'object':
    categorical_columns.append(i)

df[categorical_columns].head()

from scipy.stats import chi2_contingency

for i in categorical_columns[:-1]:
  chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))
  print(i, '---', pval)

"""Since all the values are <= 0.05 we will accept all the categorical columns."""

numerical_columns = []

for i in list(df.columns):
  if df[i].dtype != 'object' and i not in ['PROSPECTID', 'Approved_Flag']:
    numerical_columns.append(i)

print(numerical_columns)

# Calculating the VIF
vif_data = df[numerical_columns]
total_columns = vif_data.shape[1]
columns_to_keep = []
column_index = 0

for i in range(0, total_columns):
  vif_value = variance_inflation_factor(vif_data, column_index)
  print(numerical_columns[i], '-----', vif_value)

  if vif_value <= 6:
    columns_to_keep.append(numerical_columns[i])
    column_index += 1

  else:
    vif_data = vif_data.drop([numerical_columns[i]], axis = 1)

vif_data.columns

#check Anova for columns_to_be_kept

columns_to_be_kept_numerical = []

for i in columns_to_keep:
  a = list(df[i])
  b = list(df['Approved_Flag'])

  group_P1 = [value for value, group in zip(a,b) if group =='P1']
  group_P2 = [value for value, group in zip(a,b) if group =='P2']
  group_P3 = [value for value, group in zip(a,b) if group =='P3']
  group_P4 = [value for value, group in zip(a,b) if group =='P4']

  f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)

  print(i, "----", p_value)
  if p_value <= 0.05:
    columns_to_be_kept_numerical.append(i)

len(columns_to_be_kept_numerical)

categorical_columns

features = columns_to_be_kept_numerical + categorical_columns

df = df[features]

df.head()

df.shape

class EducationMapper(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.education_mapping = {
            'SSC': 1,
            '12TH': 2,
            'GRADUATE': 3,
            'UNDER GRADUATE': 3,
            'POST-GRADUATE': 4,
            'OTHERS': 1,
            'PROFESSIONAL': 3
        }

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X['EDUCATION'] = X['EDUCATION'].map(self.education_mapping)
        return X

# Define the OneHotEncoder for the categorical columns
ohe = OneHotEncoder(sparse_output=False, drop='first')

# Columns to apply OneHotEncoder to
cat_columns = ['MARITALSTATUS', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']

# Apply OneHotEncoder via ColumnTransformer
column_transformer = ColumnTransformer(
    transformers=[
        ('education_mapper', EducationMapper(), ['EDUCATION']),
        ('onehot', ohe, cat_columns),
        ('num', 'passthrough', columns_to_be_kept_numerical)  # Pass through numerical columns unchanged
    ]
)

# Separately encode the target column
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(df['Approved_Flag'])

# Split the dataset into features and target
X = df.drop(columns=['Approved_Flag'],axis = 1)

# Fit the transformer and transform the data
X_transformed = column_transformer.fit_transform(X)

# Convert the result back to a DataFrame with appropriate column names
# Get the feature names created by the OneHotEncoder
encoded_columns = column_transformer.named_transformers_['onehot'].get_feature_names_out(cat_columns)

# Combine the encoded categorical columns and numerical column names
all_columns = list(encoded_columns) + columns_to_be_kept_numerical + ['EDUCATION']

# Convert the transformed data back into a DataFrame
X_encoded = pd.DataFrame(X_transformed, columns=all_columns)

# Display the resulting encoded DataFrame
X_encoded.info()

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)

model = xgb.XGBClassifier(objective='multi:softmax',
                                       num_class=4,
                                       colsample_bytree = 0.5,
                                       learning_rate = 1.0,
                                       max_depth = 3,
                                       alpha = 10,
                                       n_estimators = 100,random_state = 42)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy_score(y_test,y_pred)

from sklearn.model_selection import GridSearchCV

# Define the XGBClassifier with the initial set of hyperparameters
xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)

# Define the parameter grid for hyperparameter tuning

param_grid = {
  'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],
  'learning_rate'   : [0.001, 0.01, 0.1, 1],
  'max_depth'       : [3, 5, 8, 10],
  'alpha'           : [1, 10, 100],
  'n_estimators'    : [10,50,100]
}

grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Print the best hyperparameters
print("Best Hyperparameters:", grid_search.best_params_)

# Evaluate the model with the best hyperparameters on the test set
best_model = grid_search.best_estimator_
accuracy = best_model.score(X_test, y_test)
print("Test Accuracy:", accuracy)

